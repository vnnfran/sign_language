Classes:
ELEMENTARY VERSION (20)
* Vowels a, e, i, o, u and numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
* I love you, yes, no, hello, sorry

TEST RUN VERSION (5):
* I love you, yes, no, hello, sorry

Main libraries used:
* OpenCV: Get real-time video input and manage accordingly.
* CVZONE: Use the Hand Tracking module; Mediapipe wrapper to simplify use.
* Pytorch: Train an ANN to recognize some sign language gestures.
* NumPy, os, time and pickle

Project phases:
1. Set up virtual environment. - Done
2. Install required libraries. - Done
3. Test camera connection. - Done
4. Configure mediapipe. - Done
5. Test hand marker recognition. - Done
6. Code script for picture collection. - Done
7. Take pictures.
8. Code script for ANN training.
9. Train ANN.
10. Test ANN.
11. Set up real-time implementation.
12. Tests.
13. Presentation.
Extra: Repeat for a CNN model and compare.

Activating the venv:
.venv\Scripts\activate

Run files directly in the Python terminal using:
python {filename}.py